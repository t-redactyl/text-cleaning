{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "texts = pd.read_csv(\"/Users/jodieburchell/Documents/text-mining/02 Text cleaning/cleansed_data.csv\",\n",
    "                    usecols=[1, 2])\n",
    "english_freqs = pd.read_csv(\"/Users/jodieburchell/Documents/text-mining/02 Text cleaning/english_term_frequencies.csv\",\n",
    "                           usecols=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsample = pd.melt(sample.iloc[:,0:16], id_vars = ['titles'], \n",
    "                  value_vars = sample.iloc[:,0:16].columns[1:],\n",
    "                  var_name = 'term', value_name = 'frequency')\n",
    "gsample['frequency'] = gsample['frequency'] - 1\n",
    "gsample\n",
    "gsample.to_csv(\"/Users/jodieburchell/Documents/text-mining/03 Document similarity/prop_frequency_sample.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "* Why is raw term frequency not helpful (because documents are of different lengths, therefore the frequency of terms means different things in different contexts)\n",
    "* Frequency needs to be divided by the number of words in a document (i.e., it is the proportion of all signal words in a document).(https://stanford.edu/~rjweiss/public_html/IRiSS2013/text2/notebooks/tfidf.html) \n",
    "* However, even if a term is frequent within one document, it might be frequent also in *all* documents. Therefore, its rarity within the corpus of documents can be determined.\n",
    "* If a term is common in one or a few documents, and rare in the corpus (only occurs in a few documents), it is likely to be highly useful for determining what that document is about.\n",
    "\n",
    "* Now I need to work out how to do the cosine similarity - I think there is an extra step where you need to normalise the length? Look into this.\n",
    "\n",
    "* Ok, now we can set the weights for each of the words, and then calculate the cosine similarity between one of the texts (leave out of the training set?) and a \"query\" (something like 'beautiful princess')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Calculating the similarity between documents\n",
    "\n",
    "In the last chapter, we covered how we could extract a clean, normalised bag-of-words from our collections of tales. In this chapter, we are going to start doing something useful with them. Specifically, we are going to have a look at the frequency of terms within our tales in order to work out which of them are the most similar. Moreover, we will work out how to retrieve those documents that are most similar to a certain set of terms. Going forward, we'll only use the English-language tales, but you can use all of the techniques I'll cover in this and all of the remaining chapters for most languages.\n",
    "\n",
    "We'll pick up where we left off at the end of the last chapter, using our cleansed body of tales. If you haven't prepared your own data set, you can download it from [here](https://github.com/t-redactyl/text-mining/blob/master/02%20Text%20cleaning/cleansed_data.csv).\n",
    "\n",
    "## Term frequency\n",
    "As we saw in the previous chapter, one of the most basic things we can do once we've cleaned and tokenised our documents is to take a frequency count of all of the words. Let's revisit this now for our corpus of fairytales, this time having a look at the top 15 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say</td>\n",
       "      <td>3026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>come</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thou</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>king</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>take</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>see</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>can</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>little</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>give</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>man</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>get</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>away</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thee</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      term  frequency\n",
       "0      say       3026\n",
       "1       go       2283\n",
       "2     come       1680\n",
       "3     will       1529\n",
       "4     thou       1501\n",
       "5     king       1199\n",
       "6     take       1139\n",
       "7      see       1038\n",
       "8      can       1004\n",
       "9   little        995\n",
       "10    give        849\n",
       "11     man        761\n",
       "12     get        715\n",
       "13    away        700\n",
       "14    thee        650"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "\n",
    "english_tokens = [word_tokenize(text) for text in texts['english_tales']]\n",
    "flat_list = [word for sent_list in english_tokens for word in sent_list]\n",
    "english_freqs = FreqDist(word for word in flat_list)\n",
    "\n",
    "ftales = DataFrame(english_freqs.most_common(15), columns=['term', 'frequency'])\n",
    "ftales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ftales = DataFrame(english_freqs.most_common(15), columns=['term', 'frequency'])\n",
    "#ftales.to_csv(\"/Users/jodieburchell/Documents/text-mining/03 Document similarity/raw_frequency_sample.csv\",\n",
    "#              index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot the frequencies of these terms, we can get a sense of how relatively common these terms are.\n",
    "\n",
    "<img src=\"/figure/Chapter 3.1.png\" title=\"Frequency graph 1\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "One thing that might have occurred to you is that because we are using the raw terms, words that are common in longer stories will be overrepresented. If we have a look at the length of the longest versus the shortest tales, we can get a sense of how unbalanced the representation is across tales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>total words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>The Two Brothers</td>\n",
       "      <td>3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Brother Lustig</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Wishing-Table, The Gold-Ass, and the Cudge...</td>\n",
       "      <td>1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>The Goose-Girl at the Well</td>\n",
       "      <td>1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Story of the Youth who Went Forth to Learn...</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  total words\n",
       "59                                    The Two Brothers         3735\n",
       "80                                      Brother Lustig         1942\n",
       "35   The Wishing-Table, The Gold-Ass, and the Cudge...         1838\n",
       "179                         The Goose-Girl at the Well         1784\n",
       "3    The Story of the Youth who Went Forth to Learn...         1749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>total words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Knoist and his Three Sons</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>The Wilful Child</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>A Riddling Tale</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Stories about Snakes</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>The Two Travellers</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  total words\n",
       "137  Knoist and his Three Sons           72\n",
       "116           The Wilful Child           63\n",
       "160            A Riddling Tale           59\n",
       "104       Stories about Snakes           54\n",
       "106         The Two Travellers           44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "tale_length = DataFrame({\n",
    "    'title': [sentence.replace(\"Brothers Grimm fairy tales -\", \"\").replace(\"(Margaret Hunt)\", \"\").lstrip().rstrip() \n",
    "               for sentence in texts['english_titles']],\n",
    "    'total words': [len(tale.split()) for tale in texts['english_tales']]})\n",
    "display(tale_length.sort_values('total words', ascending=False).head())\n",
    "display(tale_length.sort_values('total words', ascending=False).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the longest tale, *The Two Brothers*, is a whopping 85 times longer than the shortest tale, *The Two Travellers*. This means that our term frequencies will be dominated by those terms occurring in the longer tale, making it hard to work out what defines the other tales in our corpus.\n",
    "\n",
    "Another thing you might have noticed is that the most frequent term in the corpus, *say*, is around 3 times as common as most other words in the top 15. While more frequent terms do have more importance than less frequent terms in a document or corpus, this relationship is not linear. In other words, a term that occurs 200 times shouldn't be considered 10 times more important than a term that occurs 20 times - after a certain number of occurences, the presence of that common term is not adding any more information about its importance. \n",
    "\n",
    "## Normalised term frequency\n",
    "One way we can control for these problems caused by using raw frequencies is to normalise them, either on the basis of document length (i.e., convert it into a proportion) or on some other scale. One of the most popular methods (and the one used by Scikit-Learn) is called the [sublinear term frequency](https://nlp.stanford.edu/IR-book/html/htmledition/sublinear-tf-scaling-1.html). In less mysterious terms, all we are doing is taking the log of each frequency and then adding 1 **[why do we add 1??]**. By converting the frequencies into a log scale, it helps to dampen these very frequent terms and make them more proportional to less common terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.995732273553991"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6.298317366548036"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "tf1 = 20\n",
    "tf2 = 200\n",
    "\n",
    "def subl_tf(freq):\n",
    "    return 1 + math.log(freq)\n",
    "\n",
    "display(subl_tf(tf1))\n",
    "display(subl_tf(tf2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our second term frequency has been weighted, so that instead of being 10 times as large as the first term frequency it is not even twice as large!\n",
    "\n",
    "Let's convert our top 15 most frequent terms from raw to sublinear term frequencies and see what difference it makes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say</td>\n",
       "      <td>9.014997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>8.733246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>come</td>\n",
       "      <td>8.426549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will</td>\n",
       "      <td>8.332369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thou</td>\n",
       "      <td>8.313887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>king</td>\n",
       "      <td>8.089243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>take</td>\n",
       "      <td>8.037906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>see</td>\n",
       "      <td>7.945051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>can</td>\n",
       "      <td>7.911747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>little</td>\n",
       "      <td>7.902743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>give</td>\n",
       "      <td>7.744059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>man</td>\n",
       "      <td>7.634633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>get</td>\n",
       "      <td>7.572283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>away</td>\n",
       "      <td>7.551080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thee</td>\n",
       "      <td>7.476972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      term  frequency\n",
       "0      say   9.014997\n",
       "1       go   8.733246\n",
       "2     come   8.426549\n",
       "3     will   8.332369\n",
       "4     thou   8.313887\n",
       "5     king   8.089243\n",
       "6     take   8.037906\n",
       "7      see   7.945051\n",
       "8      can   7.911747\n",
       "9   little   7.902743\n",
       "10    give   7.744059\n",
       "11     man   7.634633\n",
       "12     get   7.572283\n",
       "13    away   7.551080\n",
       "14    thee   7.476972"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftales = DataFrame(english_freqs.most_common(15), columns=['term', 'frequency'])\n",
    "ftales['frequency'] = ftales['frequency'].apply(subl_tf)\n",
    "ftales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftales.to_csv(\"/Users/jodieburchell/Documents/text-mining/03 Document similarity/prop_frequency_sample.csv\",\n",
    "              index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"/figure/Chapter 3.2.png\" title=\"Frequency graph 2\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "We can now see that all of our top 15 terms have relatively similar weighting, which makes a lot more sense than what we saw in the raw frequencies. For example, in the raw frequencies *thou* was weighted as almost 3 times as important as *thee*, whereas in the normalised frequencies these words are roughly equivalent. However, you might have noticed *another* problem we now have. While we got rid of stop words in the cleaning process, the top 15 words are still dominated by words like *say*, *come* and *go*, which don't really offer much unique information as to what each story is about. Luckily, there is another way we can deal with this, which we'll discuss in the next section.\n",
    "\n",
    "## Inverse document frequency\n",
    "As a testament to how unhelpful common words can be in discriminating between documents, lets have a look at the document frequency of our most common term, *say*. This is the number of documents that this word occurs in at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tales containing 'say': 198\n",
      "Total number of tales: 211\n"
     ]
    }
   ],
   "source": [
    "csay = [tale.count(' say ') for tale in texts['english_tales']]\n",
    "print(\"Number of tales containing 'say':\"), \n",
    "print(len([x for x in csay if x != 0]))\n",
    "\n",
    "print(\"Total number of tales:\"), \n",
    "print(len(csay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that of the 211 tales, *say* occurs in 198 of them! What we need to do is add some sort of weighting that penalises terms that occur in too many documents to really offer meaningful information about their content. We can achieve this using the inverse document frequency (IDF).\n",
    "\n",
    "To calculate this, we take the inverse of the document frequency (i.e., divide the total number of documents in the corpus by the document frequency of a term), and then take the log of this. Documents that occur in many documents have a smaller IDF, while those that occur in few documents have a higher IDF. Let's have a look at a practical example. We already have our most common term *say*, so we'll contrast that with a term that occurs a very low number of times (I've arbitrarily picked the first term with a raw frequency of 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chain', 20)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_terms = {k: v for k, v in english_freqs.iteritems() if v == 20}\n",
    "rare_terms.items()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've extracted the term *chain*. Let's have a look at its document frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in [tale.count(' chain ') for tale in texts['english_tales']] if x != 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the IDF of both of these terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IDF of 'say' is 0.064\n",
      "The IDF of 'chain' is 3.406\n"
     ]
    }
   ],
   "source": [
    "N = 211\n",
    "df_say = 198\n",
    "df_chain = 7\n",
    "\n",
    "idf_say = math.log(N * 1.0 / df_say)\n",
    "idf_chain = math.log(N * 1.0 / df_chain)\n",
    "\n",
    "print(\"The IDF of 'say' is\"),\n",
    "print(round(idf_say, 3))\n",
    "\n",
    "print(\"The IDF of 'chain' is\"),\n",
    "print(round(idf_chain, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our rare term, *chain*, is given a far higher IDF than our common term *say*.\n",
    "\n",
    "## Pulling it together with tf-idf\n",
    "\n",
    "We can now tie our normalised term frequency (TF) together with the inverse document frequency (IDF) by calculating the TF-IDF. As you might have guessed from the name, the TF-IDF is simply the product of the TF and the IDF for a term. Let's have a look at the TF-IDF for our example words *say* and *chain*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
