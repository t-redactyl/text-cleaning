{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Calculating the similarity between documents\n",
    "\n",
    "Continue here - I need to make a decision about whether this is in the same chapter with tf-idf or not. Probably as otherwise the end of that chapter will involve manually calculating the tf-idf for every word, as well as being a bit boring and anti-climatic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the corpus\n",
    "\n",
    "[I should put the frequencies of the original corpus here as well - this will just tie together this chapter to the previous chapter and orientate the reader to the chapter.]\n",
    "\n",
    "Let's put together an example set, but this would also include all of the fairytales as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    'The princess was clever',\n",
    "    'The prince was handsome',\n",
    "    'The prince loved the clever princess',\n",
    "    '\"Prince, handsome prince\", said the princess',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the index vocabulary\n",
    "\n",
    "Index vocabulary is simply a numbered list of 'features' (i.e., terms) in our corpus. It includes (unless we explicitly define it) every word in the corpus, hence another reason to get rid of stop words early. These will also be the columns on the term-document matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_vocabulary = {\n",
    "    1: 'clever',\n",
    "    2: 'handsome',\n",
    "    3: 'loved',\n",
    "    4: 'prince',\n",
    "    5: 'princess',\n",
    "    6: 'said'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'clever', 2: 'handsome', 3: 'loved', 4: 'prince', 5: 'princess', 6: 'said'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning documents into vectors\n",
    "\n",
    "To turn a document into a vector, we simply need to count the number of time each term in the index vocabulary occurs in that document. Note that I need to strip out the punctuation and convert the words to lowercase. For the first document (sentence) in the corpus, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def count(document_list, term):\n",
    "    doc = document_list.lower().translate(None, string.punctuation).split()\n",
    "    match = [x for x in doc if x == term] \n",
    "    return len(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The princess was clever'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = [count(documents[0], x) for x in index_vocabulary.values()]\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also represent this a bit more explicitly with a labelled dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clever  handsome  loved  prince  princess  said\n",
       "0       1         0      0       0         1     0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame(m1).T\n",
    "df.columns = index_vocabulary.values()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 0],\n",
       "       [0, 1, 0, 2, 1, 1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tf_matrix = np.array(tuple([count(d, x) for x in index_vocabulary.values()] for d in documents))\n",
    "tf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clever  handsome  loved  prince  princess  said\n",
       "0       1         0      0       0         1     0\n",
       "1       0         1      0       1         0     0\n",
       "2       1         0      1       1         1     0\n",
       "3       0         1      0       2         1     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(np.array(tuple([count(d, x) for x in index_vocabulary.values()] for d in documents)),\n",
    "          columns = index_vocabulary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'clever', 0),\n",
       " (u'handsome', 1),\n",
       " (u'loved', 2),\n",
       " (u'prince', 3),\n",
       " (u'princess', 4),\n",
       " (u'said', 5)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import operator\n",
    "from pprint import pprint\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "vectorizer.fit_transform(documents)\n",
    "sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 3)\t2\n",
      "  (3, 4)\t1\n",
      "  (3, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "smatrix = vectorizer.transform(documents)\n",
    "print smatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 2, 1, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smatrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clever  handsome  loved  prince  princess  said\n",
       "0       1         0      0       0         1     0\n",
       "1       0         1      0       1         0     0\n",
       "2       1         0      1       1         1     0\n",
       "3       0         1      0       2         1     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(smatrix.todense(), columns = index_vocabulary.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term frequency-inverse document frequency\n",
    "\n",
    "You might have already noticed a problem with using the raw frequency of words to characterise our documents. If we have a look at the term frequencies of our Grimm's fairytale corpus, we can see that our top 20 is dominated by words like 'say', 'go' and 'come'. These words are likely to occur with a high frequency in pretty much all of the tales, and therefore don't help us identify the unique topics of specific stories. What we want to do is weight the terms within a story so that terms that  occur many times within a small number of documents have the highest weight, and those that occur within all documents have the lowest weight. We can then determine which terms are most characteristic of specific documents.\n",
    "\n",
    "We can do this with something called the term frequency-inverse document frequency, or tf-idf. This is simply a multiplication of the term frequencies in our document with something called the inverse document frequency (idf). Let's first cover how to calculate the idf before we move on to weighting the terms in our matrix.\n",
    "\n",
    "In a general sense, the idf is simply some variant of dividing the total number of documents in a corpus by the number of documents the term of interest occurs in (or in other words, its document frequency). We'll use the [formula used by sklearn](http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting) in order to keep everything consistent in this chapter, which is calculated by:\n",
    "\n",
    "$$idf(t) = log\\frac{1 + n_d}{1 + df(d,t)} +1$$\n",
    "\n",
    "In plain text, this means we add 1 to both the total number of documents ($n_d$) and the document frequency ($df(d,t)$) then divide this modified total number of documents by the modified document frequency. We then take the log of that, and add 1 to the whole thing. The reason for the additions of 1 to $n_d$ and $df(d,t)$ is to prevent divisions by zero, and the reason 1 is added to the final idf is so that terms that occur in every document don't get given a weighting of 0. Let's have a look at what the idf would be for our first term, 'clever':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The idf of 'clever' is 1.51.\n"
     ]
    }
   ],
   "source": [
    "# There are 4 documents\n",
    "n = 4.0\n",
    "\n",
    "# Clever occurs in 2 of them\n",
    "df = 2.0\n",
    "\n",
    "idf = math.log((1 + n) / (1 + df)) + 1\n",
    "print(\"The idf of 'clever' is %0.2f.\") % idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep going and calculate the idf for each of the terms in our example corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.510826</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clever  handsome     loved    prince  princess      said\n",
       "0  1.510826  1.510826  1.916291  1.223144  1.223144  1.916291"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function to clean up the string and strip out punctuation and case\n",
    "def split_docs(document):\n",
    "    doc = document.lower().translate(None, string.punctuation).split()\n",
    "    return doc\n",
    "\n",
    "# Calculate total number of documents in corpus\n",
    "total_docs = len(documents)\n",
    "\n",
    "# Calculate 1 + document frequency for each term in our vocabulary\n",
    "term_dfs = [1.0 + len([count for count in [split_docs(tale).count(term) for tale in documents] \n",
    "                       if count != 0]) for term in index_vocabulary.values()]\n",
    "\n",
    "# Calculate each idf\n",
    "idfs = [math.log(y) + 1 for y in [(total_docs + 1) / x for x in term_dfs]]\n",
    "\n",
    "# Print idfs with \n",
    "df = DataFrame(idfs).T\n",
    "df.columns = index_vocabulary.values()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We now have all of our idfs. We can now move on to calculating the tf-idf. What we need to do is to our term frequencies and the inverse document frequencies. In applied terms, what this means is that we multiply each term frequency in a document by its associated idf. Let's have a look at a practical example for our fourth sentence. Our term frequency vector is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our idfs are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5108256237659907,\n",
       " 1.5108256237659907,\n",
       " 1.916290731874155,\n",
       " 1.2231435513142097,\n",
       " 1.2231435513142097,\n",
       " 1.916290731874155]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So multiplying them together would look like:\n",
    "\n",
    "$\\begin{bmatrix}1\\times1.51 & 0\\times1.51 & 0\\times1.92 & 0\\times1.22 & 1\\times1.22 & 0\\times1.92 \\end{bmatrix}$\n",
    "\n",
    "which then simplifies to:\n",
    "\n",
    "$\\begin{bmatrix}1.51 & 0.00 & 0.00 & 0.00 & 1.22 & 0.00 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now automate this for every document in our corpus and again pop it into a DataFrame with the vocabulary terms as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.916291</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.510826</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.446287</td>\n",
       "      <td>1.223144</td>\n",
       "      <td>1.916291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clever  handsome     loved    prince  princess      said\n",
       "0  1.510826  0.000000  0.000000  0.000000  1.223144  0.000000\n",
       "1  0.000000  1.510826  0.000000  1.223144  0.000000  0.000000\n",
       "2  1.510826  0.000000  1.916291  1.223144  1.223144  0.000000\n",
       "3  0.000000  1.510826  0.000000  2.446287  1.223144  1.916291"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idfs = [y * idfs for y in tf_matrix]\n",
    "DataFrame(tf_idfs, columns = index_vocabulary.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector normalisation\n",
    "\n",
    "Raw term frequency can be misleading, as it weights towards very high occurrences of a term within a document, either because of keyword spamming or simply the length of the document. We can address this by normalising the vector. [Play with normalised and non-normalised vector for cosine similarity later and see how that looks.]\n",
    "\n",
    "To normalise a vector, we simply need to change all of the values so that they add up to 1. To do this, we divide it by the length of the vector, or it's norm, and this norm can be calculated in a couple of ways. \n",
    "\n",
    "### L2-norm\n",
    "In the diagram below, you can see that I've plotted the terms which have a non-zero frequency from the first matrix. You can I've plotted 'princess' on the x-axis, and 'clever' on the y-axis. As this document has a raw term frequency of 1 for each, we pop a point at (1, 1). If we draw a direct line between the origin and this point, how do we calculate the length of it? \n",
    "\n",
    "[graph 1 here - dot and line only]\n",
    "\n",
    "Well, you might have noticed that when you draw lines between the origin and (0,1) and (1,0), this forms a right angle triangle. \n",
    "\n",
    "[graph 2 here - triangle]\n",
    "\n",
    "We can now dust off our high school maths, and use Pythagoras's theorem to calculate the length of the vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the vector is 1.414.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "l2_norm_0 = math.sqrt(sum([i ** 2 for i in tf_matrix[0]]))\n",
    "print(\"The length of the vector is %0.3f.\") % l2_norm_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is known as the L2-norm, and can be generalised a vector of any length. For example, for the 4th document in our example set the L2-norm would be calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the vector is 2.646.\n"
     ]
    }
   ],
   "source": [
    "l2_norm_3 = math.sqrt(sum([i ** 2 for i in tf_matrix[3]]))\n",
    "print(\"The length of the vector is %0.3f.\") % l2_norm_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1-norm\n",
    "\n",
    "[graph 3 here - dot and Manhattan distance only]\n",
    " \n",
    "There is another way of calculating the distance between the origin and the point representing our term frequencies. Rather than taking the most direct path to the point (also known as the Euclidean distance), we can calculate what is called the Manhattan distance. This distance measure follows the most direct non-diagonal (like if a cab was trying to drive through Manhattan!), and is therefore simply the sum of all of its horizontal and vertical components. If we add up all of the lines in the graph above, you can see that it is 2, or in other words, just a sum of all of the term frequencies in the vector. Let's confirm this with our first vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the vector is 2.\n"
     ]
    }
   ],
   "source": [
    "l1_norm_0 = sum(tf_matrix[0])\n",
    "print(\"The length of the vector is %d.\") % l1_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we use these norms to normalise our vectors? Well, we simply divide our raw vector by our normalised vector. Easy peasy!\n",
    "\n",
    "In the case of the L1-norm, you can see that the normalised vector adds up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0. ,  0. ,  0. ,  0.5,  0. ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_matrix[0] * 1.0 / l1_norm_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the L2-norm, the *squared* results add to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49999999999999989, 0.0, 0.0, 0.0, 0.49999999999999989, 0.0]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf**2 for tf in tf_matrix[0] * 1.0 / l2_norm_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now normalise our vectors. We can do so using the below list comprehensions, which divide each term in a vector by its L2-norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.777221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629228</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.629228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.505100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640655</td>\n",
       "      <td>0.408922</td>\n",
       "      <td>0.408922</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.667400</td>\n",
       "      <td>0.333700</td>\n",
       "      <td>0.522805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     clever  handsome     loved    prince  princess      said\n",
       "0  0.777221  0.000000  0.000000  0.000000  0.629228  0.000000\n",
       "1  0.000000  0.777221  0.000000  0.629228  0.000000  0.000000\n",
       "2  0.505100  0.000000  0.640655  0.408922  0.408922  0.000000\n",
       "3  0.000000  0.412186  0.000000  0.667400  0.333700  0.522805"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_freqs = [[term / math.sqrt(sum([num ** 2 for num in vec])) for term in vec] for vec in tf_idfs]\n",
    "DataFrame(normed_freqs, columns = index_vocabulary.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just double-check that our vectors add to 1. We'll take the first vector, square each of the terms and add them. As all of the terms with a frequency of 0 won't contribute to the total, we'll just use the frequencies for 'clever' and 'princess':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_freqs[0][0]**2 + normed_freqs[0][4]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add what we've learned about the tf-idf and vector normalisation together with the earlier work we did in Scikit-Learn. We'll first reuse the raw frequency matrix we created earlier in this chapter, and apply both the tf-idf and vector normalisation to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 2, 1, 1]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_freq_matrix = smatrix.todense()\n",
    "raw_freq_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `TfidfTransformer` method to transform our matrix. The first thing we want to do is to get the idf weights by running the `fit` function over our raw frequency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "weights = TfidfTransformer(norm = 'l2')\n",
    "weights.fit(raw_freq_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the idf weights by calling the `idf_` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.51082562,  1.51082562,  1.91629073,  1.22314355,  1.22314355,\n",
       "        1.91629073])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully these look familiar! We've gotten the same result we did by calculating the results by hand earlier in this chapter. We can now use the `transform` method to both calculate the tf-idf and apply the L2-normalisation to each vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.77722116,  0.        ,  0.        ,  0.        ,  0.62922751,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.77722116,  0.        ,  0.62922751,  0.        ,\n",
       "          0.        ],\n",
       "        [ 0.5051001 ,  0.        ,  0.64065543,  0.40892206,  0.40892206,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.41218562,  0.        ,  0.66739957,  0.33369979,\n",
       "          0.5228052 ]])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_matrix = weights.transform(raw_freq_matrix)\n",
    "normed_matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can see we've gotten the exact same result as we did with our manual calculations. Now we can move onto something a bit more interesting - using these weights to work out what documents are similar.\n",
    "\n",
    "## Cosine similarity\n",
    "\n",
    "In order to work out how similar documents are, we can use something called the cosine similarity. Cosine, as in trigonometry? Yep, the same one. To make this more concrete, imagine we we had three documents, and we were trying to work out which ones are the most related based on the signal words 'clever' and 'princess'. The frequencies of these words in each of our imaginary documents is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>clever</th>\n",
       "      <th>princess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Document 1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Document 2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Document 3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Document  clever  princess\n",
       "0  Document 1       2         7\n",
       "1  Document 2       2         9\n",
       "2  Document 3       2         1"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame([['Document 1', 2, 7], ['Document 2', 2, 9], ['Document 3', 2, 1]], \n",
    "          columns = ['Document', 'clever', 'princess'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that documents 1 and 2 have very similar frequencies of both of our signal words, they are likely to be more closely related to each other than to the third document. We can make this a bit easier to see by plotting each of these points and draw a line between them and the origin, like we did earlier in the chapter. Remember that these lines are the representation of our document vectors when we only have 2 terms.\n",
    "\n",
    "[graph 4 here - vectors]\n",
    "\n",
    "You can see that the angle between the document 1 and document 2 vectors is much smaller than the angle between document 1 and document 3. But how much smaller? It might have occurred to you that, like when I was talking about vector normalisation, we can join two of the vectors and create a triangle. More specifically, we can make the last side perpendicular to the bottom vector to form a right angle triangle!\n",
    "\n",
    "[graph 5 here - triangle 1]\n",
    "[graph 6 here - triangle 2]\n",
    "\n",
    "This should hopefully be looking like familiar territory. However, to quickly get those of you up to speed who haven't touched trigonometry since high school, the cosine is one of three ways to calculate the (non-perpendicular) angles on the inside of a right-angled triangle. It ranges from 1 to -1, with smaller angles having a value closer to 1. If you need a quick refresher on the cosine, [this page](https://www.khanacademy.org/math/trigonometry/trigonometry-right-triangles) has a good overview.\n",
    "\n",
    "When we apply the cosine to vectors, we call it the cosine similarity. As tf-idf vectors normalise to 1, they can't be negative. As such, the cosine similarity in this context only ranges from 1 to 0, with documents that are very similar having a cosine similarity close to 1, while documents that are unrelated having a cosine similarity close to 0. \n",
    "\n",
    "Turns out we can calculate the cosine similarity simply using the information we have in our vectors. In order to get the cosine similarity, we first take the L2-norm of each vector and add them together. We then take the dot product of the two vectors - in other words, we multiply the first element in vector 1 by the first element in vector 2, repeat for all of the elements of each vector, and then sum the result. Finally, we divide the dot product of the vectors by the sum of the two normed vectors. And voila! We have the cosine similarity of our documents. \n",
    "\n",
    "Let's see how this looks with our example documents. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check - do you apply the term frequency to the raw frequency vector before you multiply it by the idf?\n",
    "Steps:\n",
    "* Calculate raw frequency vectors\n",
    "* Apply sublinear term frequency\n",
    "* Multiply by idf\n",
    "* Apply L2-normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words = 'english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "print tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        ,  0.6498795 ,  0.20997309]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.77722116  0.          0.          0.          0.62922751  0.        ]\n",
      " [ 0.          0.77722116  0.          0.62922751  0.          0.        ]\n",
      " [ 0.5051001   0.          0.64065543  0.40892206  0.40892206  0.        ]\n",
      " [ 0.          0.41218562  0.          0.66739957  0.33369979  0.5228052 ]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_norm = math.sqrt(0.77722116**2 + 0.62922751**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_norm= math.sqrt(0.5051001**2 + 0.64065543**2 + 0.40892206**2 + 0.40892206**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_d2_dp = 0.77722116 * 0.5051001 + 0 * 0 + 0 * 0.64065543 + 0 * 0.40892206 + 0.62922751 * 0.40892206 + 0 * 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6498795003666787"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_d1_d2 = d1_d2_dp / (d1_norm * d2_norm)\n",
    "cos_d1_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.467482665987525"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.degrees(math.acos(cos_d1_d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1 = [2, 7]\n",
    "m2 = [2, 9]\n",
    "m3 = [2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1_d2_dp = (2 * 2 + 7 * 9)\n",
    "d1_norm = math.sqrt(2**2 + 7**2)\n",
    "d2_norm = math.sqrt(2**2 + 9**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9982226157912001"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_d1_d2 = d1_d2_dp / (d1_norm * d2_norm)\n",
    "cos_d1_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4165881917711833"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.degrees(math.acos(cos_d1_d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1_d3_dp = (2 * 2 + 7 * 1)\n",
    "d3_norm = math.sqrt(2**2 + 2**1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6168493695012488"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_d1_d3 = d1_d3_dp / (d1_norm * d3_norm)\n",
    "cos_d1_d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.91357798684324"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.degrees(math.acos(cos_d1_d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
