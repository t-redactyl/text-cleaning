{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Calculating the similarity between documents\n",
    "\n",
    "Continue here - I need to make a decision about whether this is in the same chapter with tf-idf or not. Probably as otherwise the end of that chapter will involve manually calculating the tf-idf for every word, as well as being a bit boring and anti-climatic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to find a good step-by-step tutorial of constructing the tf-idf matrix by hand\n",
    "# Then I need to find another step-by-step of the cosine similarity\n",
    "# I should work through both of those completely before I do the chapter!! :D\n",
    "# Also, I can do the graph demonstrating the document-term similarity with the tf-idf!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = (\n",
    "    \"The sky is blue\",\n",
    "    \"The sun is bright\",\n",
    "    \"The sun in the sky is bright\",\n",
    "    \"We can see the shining sun, the bright sun\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorizer.fit_transform(documents)\n",
    "print vectorizer.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "print tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'blue', 0),\n",
       " (u'bright', 1),\n",
       " (u'can', 2),\n",
       " (u'in', 3),\n",
       " (u'is', 4),\n",
       " (u'see', 5),\n",
       " (u'shining', 6),\n",
       " (u'sky', 7),\n",
       " (u'sun', 8),\n",
       " (u'the', 9),\n",
       " (u'we', 10)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "from pprint import pprint\n",
    "\n",
    "sorted(tfidf_vectorizer.vocabulary_.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.65919112  0.          0.          0.          0.42075315  0.          0.\n",
      "   0.51971385  0.          0.34399327  0.        ]\n",
      " [ 0.          0.52210862  0.          0.          0.52210862  0.          0.\n",
      "   0.          0.52210862  0.42685801  0.        ]\n",
      " [ 0.          0.3218464   0.          0.50423458  0.3218464   0.          0.\n",
      "   0.39754433  0.3218464   0.52626104  0.        ]\n",
      " [ 0.          0.23910199  0.37459947  0.          0.          0.37459947\n",
      "   0.37459947  0.          0.47820398  0.39096309  0.37459947]]\n"
     ]
    }
   ],
   "source": [
    "print tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.36651513,  0.52305744,  0.13448867]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.65919112,  0.        ,  0.        ,  0.        ,  0.42075315,\n",
       "          0.        ,  0.        ,  0.51971385,  0.        ,  0.34399327,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.52210862,  0.        ,  0.        ,  0.52210862,\n",
       "          0.        ,  0.        ,  0.        ,  0.52210862,  0.42685801,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.3218464 ,  0.        ,  0.50423458,  0.3218464 ,\n",
       "          0.        ,  0.        ,  0.39754433,  0.3218464 ,  0.52626104,\n",
       "          0.        ],\n",
       "        [ 0.        ,  0.23910199,  0.37459947,  0.        ,  0.        ,\n",
       "          0.37459947,  0.37459947,  0.        ,  0.47820398,  0.39096309,\n",
       "          0.37459947]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm = tfidf_matrix.todense()\n",
    "dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex: Find the similarity between documents 1 and 2.  \n",
    "d1 = (5, 0, 3, 0, 2, 0, 0, 2, 0, 0)  \n",
    "d2 = (3, 0, 2, 0, 1, 1, 0, 1, 0, 1)  \n",
    "d1 â‹… d2 = 5*3+0*0+3*2+0*0+2*1+0*1+0*1+2*1+0*0+0*1 = 25  \n",
    "||d1|| = (5*5+0*0+3*3+0*0+2*2+0*0+0*0+2*2+0*0+0*0)0.5 = (42) 0.5 = 6.481  \n",
    "||d2|| = (3*3+0*0+2*2+0*0+1*1+1*1+0*0+1*1+0*0+1*1)0.5 = (17) 0.5 = 4.12  \n",
    "cos(d1, d2 ) = 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dot_prod = dm.item(0, 0) * dm.item(2, 0) + dm.item(0, 1) * dm.item(2, 1) +\\\n",
    "               dm.item(0, 2) * dm.item(2, 2) + dm.item(0, 3) * dm.item(2, 3) +\\\n",
    "               dm.item(0, 4) * dm.item(2, 4) + dm.item(0, 5) * dm.item(2, 5) +\\\n",
    "               dm.item(0, 6) * dm.item(2, 6) + dm.item(0, 7) * dm.item(2, 7) +\\\n",
    "               dm.item(0, 8) * dm.item(2, 8) + dm.item(0, 9) * dm.item(2, 9) +\\\n",
    "               dm.item(0, 10) * dm.item(2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230574383703659"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_dot_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_sq = (dm.item(0, 0) * dm.item(0, 0) + dm.item(0, 1) * dm.item(0, 1) +\\\n",
    "         dm.item(0, 2) * dm.item(0, 2) + dm.item(0, 3) * dm.item(0, 3) +\\\n",
    "         dm.item(0, 4) * dm.item(0, 4) + dm.item(0, 5) * dm.item(0, 5) +\\\n",
    "         dm.item(0, 6) * dm.item(0, 6) + dm.item(0, 7) * dm.item(0, 7) +\\\n",
    "         dm.item(0, 8) * dm.item(0, 8) + dm.item(0, 9) * dm.item(0, 9) +\\\n",
    "         dm.item(0, 10) * dm.item(0, 10)) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v2_sq = (dm.item(2, 0) * dm.item(2, 0) + dm.item(2, 1) * dm.item(2, 1) +\\\n",
    "         dm.item(2, 2) * dm.item(2, 2) + dm.item(2, 3) * dm.item(2, 3) +\\\n",
    "         dm.item(2, 4) * dm.item(2, 4) + dm.item(2, 5) * dm.item(2, 5) +\\\n",
    "         dm.item(2, 6) * dm.item(2, 6) + dm.item(2, 7) * dm.item(2, 7) +\\\n",
    "         dm.item(2, 8) * dm.item(2, 8) + dm.item(2, 9) * dm.item(2, 9) +\\\n",
    "         dm.item(2, 10) * dm.item(2, 10)) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999999999999999"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49999999999999983"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5230574383703658"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_dot_prod / v1_sq * v2_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the corpus\n",
    "\n",
    "Let's put together an example set, but this would also include all of the fairytales as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    'The princess was clever',\n",
    "    'The prince was handsome',\n",
    "    'The prince loved the clever princess',\n",
    "    '\"Prince, handsome prince\", said the princess',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the index vocabulary\n",
    "\n",
    "Index vocabulary is simply a numbered list of 'features' (i.e., terms) in our corpus. It includes (unless we explicitly define it) every word in the corpus, hence another reason to get rid of stop words early. These will also be the columns on the term-document matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_vocabulary = {\n",
    "    1: 'clever',\n",
    "    2: 'handsome',\n",
    "    3: 'loved',\n",
    "    4: 'prince',\n",
    "    5: 'princess',\n",
    "    6: 'said'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'clever', 2: 'handsome', 3: 'loved', 4: 'prince', 5: 'princess', 6: 'said'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning documents into vectors\n",
    "\n",
    "To turn a document into a vector, we simply need to count the number of time each term in the index vocabulary occurs in that document. Note that I need to strip out the punctuation and convert the words to lowercase. For the first document (sentence) in the corpus, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def count(document_list, term):\n",
    "    doc = document_list.lower().translate(None, string.punctuation).split()\n",
    "    match = [x for x in doc if x == term] \n",
    "    return len(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The princess was clever'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = [count(documents[0], x) for x in index_vocabulary.values()]\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also represent this a bit more explicitly with a labelled dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clever  handsome  loved  prince  princess  said\n",
       "0       1         0      0       0         1     0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame(m1).T\n",
    "df.columns = index_vocabulary.values()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 0],\n",
       "       [0, 1, 0, 2, 1, 1]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(tuple([count(d, x) for x in index_vocabulary.values()] for d in documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clever  handsome  loved  prince  princess  said\n",
       "0       1         0      0       0         1     0\n",
       "1       0         1      0       1         0     0\n",
       "2       1         0      1       1         1     0\n",
       "3       0         1      0       2         1     1"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(np.array(tuple([count(d, x) for x in index_vocabulary.values()] for d in documents)),\n",
    "          columns = index_vocabulary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'clever', 0),\n",
       " (u'handsome', 1),\n",
       " (u'loved', 2),\n",
       " (u'prince', 3),\n",
       " (u'princess', 4),\n",
       " (u'said', 5)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import operator\n",
    "from pprint import pprint\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "\n",
    "vectorizer.fit_transform(documents)\n",
    "sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 4)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 3)\t1\n",
      "  (2, 4)\t1\n",
      "  (3, 1)\t1\n",
      "  (3, 3)\t2\n",
      "  (3, 4)\t1\n",
      "  (3, 5)\t1\n"
     ]
    }
   ],
   "source": [
    "smatrix = vectorizer.transform(documents)\n",
    "print smatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 0, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 1, 1, 0],\n",
       "        [0, 1, 0, 2, 1, 1]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smatrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clever</th>\n",
       "      <th>handsome</th>\n",
       "      <th>loved</th>\n",
       "      <th>prince</th>\n",
       "      <th>princess</th>\n",
       "      <th>said</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clever  handsome  loved  prince  princess  said\n",
       "0       1         0      0       0         1     0\n",
       "1       0         1      0       1         0     0\n",
       "2       1         0      1       1         1     0\n",
       "3       0         1      0       2         1     1"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(smatrix.todense(), columns = index_vocabulary.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
