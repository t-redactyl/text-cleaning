{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Calculating the similarity between documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/  \n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/a-first-take-at-building-an-inverted-index-1.html\n",
    "\n",
    "Good explanation of cosine similarity with two words: https://stackoverflow.com/questions/1746501/can-someone-give-an-example-of-cosine-similarity-in-a-very-simple-graphical-wa\n",
    "\n",
    "Step-by-step tutorial for calculating td-idf and how it relates to document-query similarity: http://www.site.uottawa.ca/~diana/csi4107/cosine_tf_idf_example.pdf\n",
    "\n",
    "https://stanford.edu/~rjweiss/public_html/IRiSS2013/text2/notebooks/tfidf.html\n",
    "\n",
    "https://web.stanford.edu/class/cs276/handouts/lecture6-tfidf.ppt\n",
    "\n",
    "https://cran.r-project.org/web/packages/tidytext/vignettes/tf_idf.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Working through tutorial on td-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mycorpus = ['new york times', 'new york post', 'los angeles times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['new', 'york', 'times'], ['new', 'york', 'post'], ['los', 'angeles', 'times']]\n"
     ]
    }
   ],
   "source": [
    "tokens = [word_tokenize(text) for text in mycorpus]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times: 2\n",
      "york: 2\n",
      "new: 2\n",
      "angeles: 1\n",
      "los: 1\n",
      "post: 1\n"
     ]
    }
   ],
   "source": [
    "flatList = [word for sentList in tokens for word in sentList]\n",
    "tokenFreq = FreqDist(word for word in flatList)\n",
    "\n",
    "for word, frequency in tokenFreq.most_common(10):\n",
    "    print(u'{}: {}'.format(word, frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['times', 'angeles', 'los', 'york', 'new', 'post']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate IDF\n",
    "tokenFreq['angeles']\n",
    "tokenFreq.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5849625007211563"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(len(mycorpus) / tokenFreq['angeles'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'angeles': 1.5849625007211563,\n",
       "          'los': 1.5849625007211563,\n",
       "          'new': 0.5849625007211562,\n",
       "          'post': 1.5849625007211563,\n",
       "          'times': 0.5849625007211562,\n",
       "          'york': 0.5849625007211562})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in tokenFreq:    \n",
    "    tokenFreq[key] = math.log(len(mycorpus) * 1.0 / tokenFreq[key], 2)\n",
    "    \n",
    "tokenFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'angeles': 1, 'los': 1, 'new': 2, 'post': 1, 'times': 2, 'york': 2})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('new', 1), ('york', 1), ('times', 1)]\n",
      "[('new', 1), ('post', 1), ('york', 1)]\n",
      "[('angeles', 1), ('los', 1), ('times', 1)]\n"
     ]
    }
   ],
   "source": [
    "for doc in mycorpus:\n",
    "    tf = Counter()\n",
    "    for word in doc.split():\n",
    "        tf[word] +=1\n",
    "    print tf.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary vector is [times, angeles, los, york, new, post]\n",
      "The doc is \"new york times\"\n",
      "The tf vector for Document 1 is [1, 0, 0, 1, 1, 0]\n",
      "The doc is \"new york post\"\n",
      "The tf vector for Document 2 is [0, 0, 0, 1, 1, 1]\n",
      "The doc is \"los angeles times\"\n",
      "The tf vector for Document 3 is [1, 1, 1, 0, 0, 0]\n",
      "All combined, here is our master document term matrix: \n",
      "[[1, 0, 0, 1, 1, 0], [0, 0, 0, 1, 1, 1], [1, 1, 1, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "import string #allows for format()\n",
    "    \n",
    "def build_lexicon(corpus):\n",
    "    lexicon = set()\n",
    "    for doc in corpus:\n",
    "        lexicon.update([word for word in doc.split()])\n",
    "    return lexicon\n",
    "\n",
    "def tf(term, document):\n",
    "    return freq(term, document)\n",
    "\n",
    "def freq(term, document):\n",
    "    return document.split().count(term)\n",
    "\n",
    "vocabulary = build_lexicon(mycorpus)\n",
    "\n",
    "doc_term_matrix = []\n",
    "print 'Our vocabulary vector is [' + ', '.join(list(vocabulary)) + ']'\n",
    "for doc in mycorpus:\n",
    "    print 'The doc is \"' + doc + '\"'\n",
    "    tf_vector = [tf(word, doc) for word in vocabulary]\n",
    "    tf_vector_string = ', '.join(format(freq, 'd') for freq in tf_vector)\n",
    "    print 'The tf vector for Document %d is [%s]' % ((mycorpus.index(doc)+1), tf_vector_string)\n",
    "    doc_term_matrix.append(tf_vector)\n",
    "    \n",
    "    # here's a test: why did I wrap mydoclist.index(doc)+1 in parens?  it returns an int...\n",
    "    # try it!  type(mydoclist.index(doc) + 1)\n",
    "\n",
    "print 'All combined, here is our master document term matrix: '\n",
    "print doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
