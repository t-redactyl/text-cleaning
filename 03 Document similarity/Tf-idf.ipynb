{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Calculating the similarity between documents\n",
    "\n",
    "In the last chapter, we covered how we could extract a clean, normalised bag-of-words from our collections of tales. In this chapter, we are going to start doing something useful with them. Specifically, we are going to have a look at the frequency of terms within our tales in order to work out which of them are the most similar. Moreover, we will work out how to retrieve those documents that are most similar to a certain set of terms. Going forward, we'll only use the English-language tales, but you can use all of the techniques I'll cover in this and all of the remaining chapters for most languages.\n",
    "\n",
    "We'll pick up where we left off at the end of the last chapter, using our cleansed body of tales. If you haven't prepared your own data set, you can download it from [here](https://github.com/t-redactyl/text-mining/blob/master/02%20Text%20cleaning/cleansed_data.csv).\n",
    "\n",
    "## Term frequency\n",
    "As we saw in the previous chapter, one of the most basic things we can do once we've cleaned and tokenised our documents is to take a frequency count of all of the words. Let's revisit this now for our corpus of fairytales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>say</td>\n",
       "      <td>3026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>2283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>come</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>will</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thou</td>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>king</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>take</td>\n",
       "      <td>1139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>see</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>can</td>\n",
       "      <td>1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>little</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>give</td>\n",
       "      <td>849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>man</td>\n",
       "      <td>761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>get</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>away</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>thee</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>now</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>time</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>old</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>make</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>look</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      term  frequency\n",
       "0      say       3026\n",
       "1       go       2283\n",
       "2     come       1680\n",
       "3     will       1529\n",
       "4     thou       1501\n",
       "5     king       1199\n",
       "6     take       1139\n",
       "7      see       1038\n",
       "8      can       1004\n",
       "9   little        995\n",
       "10    give        849\n",
       "11     man        761\n",
       "12     get        715\n",
       "13    away        700\n",
       "14    thee        650\n",
       "15     now        583\n",
       "16    time        568\n",
       "17     old        556\n",
       "18    make        533\n",
       "19    look        521"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "\n",
    "english_tokens = [word_tokenize(text) for text in texts['english_tales']]\n",
    "flat_list = [word for sent_list in english_tokens for word in sent_list]\n",
    "english_freqs = FreqDist(word for word in flat_list)\n",
    "\n",
    "ftales = DataFrame(english_freqs.most_common(20), columns=['term', 'frequency'])\n",
    "ftales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this a little less overwhelming by focusing on two terms: one that is common and one that is rare. For our common term, we'll randomly pull one of our terms out of the top 20. For the rare term, we'll take a term that has a frequency of 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The common term is 'make' and its frequency is 533. The rare term is 'merchant' and its frequency is 30.\n"
     ]
    }
   ],
   "source": [
    "# Choose common term and frequency\n",
    "common = {k: v for k, v in english_freqs.iteritems() if v > 520}\n",
    "common_term = common.items()[0][0]\n",
    "common_freq = common.items()[0][1]\n",
    "\n",
    "# Choose rare term and frequency\n",
    "rare = {k: v for k, v in english_freqs.iteritems() if v == 30}\n",
    "rare_term = rare.items()[0][0]\n",
    "rare_freq = rare.items()[0][1]\n",
    "\n",
    "print(\"The common term is '%s' and its frequency is %d.\") % (common_term, common_freq),\n",
    "print(\"The rare term is '%s' and its frequency is %d.\") % (rare_term, rare_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that might have occurred to you is that because we are using the raw terms, words that are common in longer stories will be overrepresented. If we have a look at the length of the longest versus the shortest tales, we can get a sense of how unbalanced the representation is across tales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>total words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>The Two Brothers</td>\n",
       "      <td>3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Brother Lustig</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Wishing-Table, The Gold-Ass, and the Cudge...</td>\n",
       "      <td>1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>The Goose-Girl at the Well</td>\n",
       "      <td>1784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Story of the Youth who Went Forth to Learn...</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  total words\n",
       "59                                    The Two Brothers         3735\n",
       "80                                      Brother Lustig         1942\n",
       "35   The Wishing-Table, The Gold-Ass, and the Cudge...         1838\n",
       "179                         The Goose-Girl at the Well         1784\n",
       "3    The Story of the Youth who Went Forth to Learn...         1749"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>total words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Knoist and his Three Sons</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>The Wilful Child</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>A Riddling Tale</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Stories about Snakes</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>The Two Travellers</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         title  total words\n",
       "137  Knoist and his Three Sons           72\n",
       "116           The Wilful Child           63\n",
       "160            A Riddling Tale           59\n",
       "104       Stories about Snakes           54\n",
       "106         The Two Travellers           44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "tale_length = DataFrame({\n",
    "    'title': [sentence.replace(\"Brothers Grimm fairy tales -\", \"\").replace(\"(Margaret Hunt)\", \"\").lstrip().rstrip() \n",
    "               for sentence in texts['english_titles']],\n",
    "    'total words': [len(tale.split()) for tale in texts['english_tales']]})\n",
    "display(tale_length.sort_values('total words', ascending=False).head())\n",
    "display(tale_length.sort_values('total words', ascending=False).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the longest tale, *The Two Brothers*, is a whopping 85 times longer than the shortest tale, *The Two Travellers*. This means that our term frequencies will be dominated by those terms occurring in the longer tale, making it hard to work out what defines the other tales in our corpus.\n",
    "\n",
    "Another thing you might have noticed is that the our common term, *make*, is around 18 times more common than our rare term, *merchant*. While more frequent terms do have more importance than less frequent terms in a document or corpus, this relationship is not linear. In other words, a term that occurs 200 times shouldn't be considered 10 times more important than a term that occurs 20 times - after a certain number of occurences, the presence of that common term is not adding any more information about its importance. \n",
    "\n",
    "## Normalised term frequency\n",
    "One way we can control for these problems caused by using raw frequencies is to normalise them, either on the basis of document length (i.e., convert it into a proportion) or on some other scale. One of the most popular methods is called the [sublinear term frequency](https://nlp.stanford.edu/IR-book/html/htmledition/sublinear-tf-scaling-1.html). In less mysterious terms, all we are doing is taking the log of each frequency and then adding 1 **[why do we add 1??]**. By converting the frequencies into a log scale, it helps to dampen these very frequent terms and make them more proportional to less common terms.\n",
    "\n",
    "Let's have a look at what this does to the frequencies for our common and rare term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalised term frequency for 'make' is 7.28, and the normalised term frequency for 'merchant' is 4.40.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def subl_tf(freq):\n",
    "    return 1 + math.log(freq)\n",
    "\n",
    "common_ntf = subl_tf(common_freq)\n",
    "rare_ntf = subl_tf(rare_freq)\n",
    "\n",
    "print(\"The normalised term frequency for '%s' is %0.2f,\") % (common_term, common_ntf),\n",
    "print(\"and the normalised term frequency for '%s' is %0.2f.\") % (rare_term, rare_ntf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that *make* has been weighted, so that instead of being 10 times as large as *merchant* it is not even twice as large! However, you might have noticed *another* problem we now have. While we got rid of stop words in the cleaning process, the top 20 words are dominated by words like *say*, *come* and *go*, which don't really offer much unique information as to what each story is about. Luckily, there is another way we can deal with this, which we'll discuss in the next section.\n",
    "\n",
    "## Inverse document frequency\n",
    "As a testament to how unhelpful common words can be in discriminating between documents, lets have a look at the document frequency of our common term, *make*. This is the number of documents that this word occurs in at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'make' occurs in 158 documents, of a total of 211.\n"
     ]
    }
   ],
   "source": [
    "total_df = len(texts['english_tales'])\n",
    "common_df = len([x for x in [tale.split(\" \").count(common_term) for tale in texts['english_tales']] \n",
    "                 if x != 0])\n",
    "print(\"'%s' occurs in %d documents, of a total of %d.\") % (common_term, common_df, total_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that of the 211 tales, *say* occurs in 158, which is three quarters of them! This is not really all that helpful for telling the tales apart. What we need to do is add some sort of weighting that penalises terms that occur in too many documents to really offer meaningful information about their content. We can achieve this using the inverse document frequency (IDF).\n",
    "\n",
    "To calculate this, we take the inverse of the document frequency (i.e., divide the total number of documents in the corpus by the document frequency of a term), and then take the log of this. Documents that occur in many documents have a smaller IDF, while those that occur in few documents have a higher IDF. Let's see how this works with our common and rare terms. We first need to calculate the document frequency for our rare term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'merchant' occurs in 9 documents, of a total of 211.\n"
     ]
    }
   ],
   "source": [
    "rare_df = len([x for x in [tale.split(\" \").count(rare_term) for tale in texts['english_tales']] \n",
    "                 if x != 0])\n",
    "print(\"'%s' occurs in %d documents, of a total of %d.\") % (rare_term, rare_df, total_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to *make*, *merchant* only occurs in 9 documents! It is likely to give us some unique information about the documents it occurs within. Let's see whether the IDF bears this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IDF of 'make' is 0.29, and the IDF of 'merchant' is 3.15.\n"
     ]
    }
   ],
   "source": [
    "def idf(N, df):\n",
    "    return math.log(N * 1.0 / df)\n",
    "\n",
    "common_idf = idf(total_df, common_df)\n",
    "rare_idf = idf(total_df, rare_df)\n",
    "\n",
    "print(\"The IDF of '%s' is %0.2f, and the IDF of '%s' is %0.2f.\") % (\n",
    "    common_term, common_idf, rare_term, rare_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the ubiquity of *make* has made it substantially less important than the much rarer *merchant*. We're ready to throw this together with our term frequency to get our final term weighting.\n",
    "\n",
    "## Pulling it together with tf-idf\n",
    "We can now tie our normalised term frequency (TF) together with the inverse document frequency (IDF) by calculating the tf-idf. As you might have guessed from the name, the tf-idf is simply the product of the TF and the IDF for a term. The tf-idf is designed to be highest when a term occurs many times within a small number of documents, and lowest when a term occurs in basically all documents. It thus offers a nice way of weighting terms so that those that are most characteristic a document have the most importance. \n",
    "\n",
    "Let's have a look at the tf-idf for our example words *make* and *merchant*. As we have already calculated our normalised term frequencies and inverse document frequencies, we simply need to multiply these together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'common_ntf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ec85ed239c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcommon_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon_ntf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcommon_idf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrare_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrare_ntf\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrare_idf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m print(\"The tf-idf of '%s' is %0.2f, and the tf-idf of '%s' is %0.2f.\") % (\n\u001b[1;32m      5\u001b[0m     common_term, common_tfidf, rare_term, rare_tfidf)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'common_ntf' is not defined"
     ]
    }
   ],
   "source": [
    "common_tfidf = common_ntf * common_idf\n",
    "rare_tfidf = rare_ntf * rare_idf\n",
    "\n",
    "print(\"The tf-idf of '%s' is %0.2f, and the tf-idf of '%s' is %0.2f.\") % (\n",
    "    common_term, common_tfidf, rare_term, rare_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the term *merchant*, which only occurs in 9 tales, has a far higher tf-idf than *make*, which offers very little unique information about any specific tale.\n",
    "\n",
    "## Calculating the tf-idf using Scikit-Learn\n",
    "To make it a bit easier to do this for every term, we can luckily pull in some handy functions from the Scikit-Learn `feature_extraction` module. The `TfidfVectorizer` takes a raw collection of documents and turns it into into a term-document matrix. This is a count of how many times each of the terms in the corpus occur in each specific document, and something we'll revisit in much more detail once we start discussing cosine similarity. It also sets up how the tf-idf will be calculated. In our case, we want to make sure we are using the sublinear term frequency normalisation, so we set this argument to `True`.\n",
    "\n",
    "We then call the `fit_transformation` method, which learns the dictionary of all words in the corpus given the input text, calculates the tf-idf according to how you've set it up, and returns the final weighting for each term in a document. Again, we'll get into this more detail in the next chapter.\n",
    "\n",
    "For now, we can have a look at the tf-idf weightings for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "sklearn_tfidf = TfidfVectorizer(sublinear_tf = True)\n",
    "sklearn_representation = sklearn_tfidf.fit_transform(texts['english_tales'])\n",
    "idf = sklearn_tfidf.idf_\n",
    "idf_weights = DataFrame({'term': sklearn_tfidf.get_feature_names(),\n",
    "           'idf': idf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>1.287682</td>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf  term\n",
       "3266  1.287682  make"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_weights[idf_weights['term'] == 'make']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3353</th>\n",
       "      <td>4.054001</td>\n",
       "      <td>merchant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idf      term\n",
       "3353  4.054001  merchant"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_weights[idf_weights['term'] == 'merchant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf = True)\n",
    "tfidf_matrix = vectorizer.fit_transform(texts['english_tales'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = tfidf_matrix.todense()\n",
    "dense\n",
    "#denselist = dense.tolist()\n",
    "#df = pd.DataFrame(denselist, columns=feature_names, index=characters)\n",
    "#s = pd.Series(df.loc['Adam'])\n",
    "#s[s > 0].sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf = True)\n",
    "tfs = tfidf.fit_transform(texts['english_tales'])\n",
    "response = tfidf.transform(texts['english_tales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms_l = []\n",
    "tfidf_l = []\n",
    "\n",
    "feature_names = tfidf.get_feature_names()\n",
    "for col in response.nonzero()[1]:\n",
    "    terms_l.append(feature_names[col])\n",
    "    tfidf_l.append(response[0, col])\n",
    "#print feature_names[col], ' - ', response[0, col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "for col in response.nonzero()[1]:\n",
    "    l.append({'term': feature_names[col], 'tfidf': response[0, col]})\n",
    "    \n",
    "tfidf_tot = DataFrame(l).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>merchant</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          term  tfidf\n",
       "2039  merchant    0.0"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_tot[tfidf_tot['term'] == 'merchant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
