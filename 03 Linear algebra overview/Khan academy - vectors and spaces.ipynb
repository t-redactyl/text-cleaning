{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Khan Academy linear algebra tutorials\n",
    "\n",
    "## Vector intro for linear algebra\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/vectors/vector-introduction-linear-algebra/)\n",
    "\n",
    "* Vectors represent an object with both **magnitude** and **direction**\n",
    "* For example, an object moving 5km/h east is a vector\n",
    "* We represent this using a Cartesian plane, where a line is drawn from an arbitrary point for the magnitude and direction of the vector\n",
    "    * For the sake of neatness, vectors usually start at the origin, though\n",
    "* In our example with the object travelling 5kms/h east, we could represent it with the line (5,0)\n",
    "* In mathematical notation, we represent the vector as:\n",
    "\n",
    "$\\vec v = \\begin{bmatrix}5\\\\0\\end{bmatrix}$ \n",
    "\n",
    "* A vector of the same magnitude but a different direction could be:\n",
    "\n",
    "$\\vec a = \\begin{bmatrix}3\\\\4\\end{bmatrix}$ \n",
    "\n",
    "* Drawing this on a Eucledian plane, we can see that we can use Pythagora's theorem to solve the length of the line ($3^2 + 4^2 = 5^2$ - or the magnitude of the line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real co-ordinate spaces\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/vectors/real-coordinate-spaces/)\n",
    "\n",
    "* The vectors above below to ${\\rm I\\!R}^2$, or the 2-dimensional real co-ordinate space, which is all possible real-valued 2-tuples:\n",
    "    * A tuple is an ordered list\n",
    "    * Therefore, ${\\rm I\\!R}^2$ represents all possible 2-value co-ordinates\n",
    "    * Co-ordinates must have real numbers\n",
    "* ${\\rm I\\!R}^3$ is an extension of this idea, and represents all possible real-valued 3-tuples\n",
    "* For example, this is belongs to ${\\rm I\\!R}^3$:\n",
    "\n",
    "$\\vec b = \\begin{bmatrix}-1\\\\7\\\\6\\end{bmatrix}$ \n",
    "\n",
    "* Naturally this idea can be extended beyond 2- or 3-dimensions, with co-ordinate spaces that it is difficult or impossible for us to represent visually being easily represented by the n-tuples\n",
    "* This is represented as ${\\rm I\\!R}^n$, or an n-dimensional real co-ordinate space\n",
    "* For example, a member of ${\\rm I\\!R}^6$ is impossible for us to represent visually, but can easily be represented as a real-valued 6-tuple:\n",
    "\n",
    "$\\vec c = \\begin{bmatrix}2\\\\5\\\\4\\\\9\\\\2\\\\3\\end{bmatrix}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplying a vector by a scalar\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/vectors/multiplying-vector-by-scalar/)\n",
    "\n",
    "* A scalar is simply a single number that you can use to *scale* your vectors.\n",
    "* In order to multiply a vector by a scalar, you multiply every element of the vector by the scalar.\n",
    "* This is represented mathematically as:\n",
    "\n",
    "$3 \\vec a = \\begin{bmatrix}3\\times3\\\\3\\times4\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}9\\\\12\\end{bmatrix}$\n",
    "\n",
    "* Multiplying a vector by a positive scalar only changes the magnitude of the vector, not the direction - in the example above, the vector is pointing in exactly the same direction, but is now 3 times longer.\n",
    "* Multiplying a vector by a negative scalar changes the direction and (potentially) the magnitude of the vector. For example, if we multiply our vector a by -1, we get:\n",
    "\n",
    "$-1 \\vec a = \\begin{bmatrix}-1\\times3\\\\-1\\times4\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}-3\\\\-4\\end{bmatrix}$\n",
    "\n",
    "In this case, the magnitude (length) of the vector has not changed, but it is now pointing in exactly the opposite direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector examples\n",
    "\n",
    "### Vector addition\n",
    "* Two vectors can be added simply by adding the corresponding elements in each vector. For example:\n",
    "\n",
    "$\\vec a = \\begin{bmatrix}-1\\\\2\\end{bmatrix}$\n",
    "\n",
    "$\\vec b = \\begin{bmatrix}3\\\\1\\end{bmatrix}$\n",
    "\n",
    "$\\vec a + \\vec b = \\begin{bmatrix}-1 + 3\\\\2 + 1\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}2\\\\3\\end{bmatrix}$\n",
    "\n",
    "* What does this represent? Looking at the image below, we can see that if we start $\\vec a$ at the origin (the **standard position**) and we start $\\vec b$ at the head of $\\vec a$, $\\vec a + \\vec b$ joins the two. This represents the addition of the two vectors (combined magnitude and direction).\n",
    "\n",
    "<img src=\"Vector addition.png\">\n",
    "\n",
    "### Vector subtraction\n",
    "* Two vectors can be subtracted in a similar manner.\n",
    "\n",
    "$\\vec a = \\begin{bmatrix}2\\\\3\\end{bmatrix}$\n",
    "\n",
    "$\\vec b = \\begin{bmatrix}-4\\\\-2\\end{bmatrix}$\n",
    "\n",
    "$\\vec a - \\vec b = \\begin{bmatrix}2 - (-4)\\\\3 - (-2)\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}2 + 4\\\\3 + 2\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}6\\\\5\\end{bmatrix}$\n",
    "\n",
    "* This represents something slightly different from adding the vectors. Looking at the image below, we can see that if we start both $\\vec a$ and $\\vec b$ at the standard position (or have them tail-to-tail, starting from any position), $\\vec a - \\vec b$ connects the two heads. It thus represents the difference between the two vectors (combined magnitude and direction).\n",
    "\n",
    "<img src=\"Vector subtraction.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric representations of lines\n",
    "\n",
    "* A line can be defined as the set of all possible coordinates where a vector $\\vec v$ is multiplied by a range of real scalars $c$. For example:\n",
    "\n",
    "$\\vec v = \\begin{bmatrix}2\\\\1\\end{bmatrix}$\n",
    "\n",
    "The line would represent all possible values of $c$. The following would all be members of the set defined by $c \\vec v$:\n",
    "\n",
    "$2 \\vec v = \\begin{bmatrix}4\\\\2\\end{bmatrix}$\n",
    "\n",
    "$5 \\vec v = \\begin{bmatrix}10\\\\5\\end{bmatrix}$\n",
    "\n",
    "$-1.5 \\vec v = \\begin{bmatrix}-3\\\\-1.5\\end{bmatrix}$\n",
    "\n",
    "This can be seen in the plot below:\n",
    "\n",
    "<img src=\"Lines as a set of vectors.png\">\n",
    "\n",
    "* A parallel line can be defined by this set of all possible coordinates of vector $\\vec v$ multiplied by any real scalar, added to any other vector $\\vec x$. For example, if vector $\\vec v$ is equal to:\n",
    "\n",
    "$\\vec v = \\begin{bmatrix}2\\\\1\\end{bmatrix}$\n",
    "\n",
    "And vector $\\vec x$ is equal to:\n",
    "\n",
    "$\\vec x = \\begin{bmatrix}2\\\\4\\end{bmatrix}$\n",
    "\n",
    "Then possible values for the parallel line would be:\n",
    "\n",
    "$\\vec v + \\vec x = \\begin{bmatrix}2 + 2\\\\1 + 4\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}4\\\\5\\end{bmatrix}$\n",
    "\n",
    "$2 \\vec v + \\vec x = \\begin{bmatrix}4 + 2\\\\2 + 4\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}6\\\\6\\end{bmatrix}$\n",
    "\n",
    "$5 \\vec v + \\vec x = \\begin{bmatrix}10 + 2\\\\5 + 4\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}12\\\\9\\end{bmatrix}$\n",
    "\n",
    "$-1.5 \\vec v + \\vec x = \\begin{bmatrix}-3 + 2\\\\-1.5 + 4\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}-1\\\\2.5\\end{bmatrix}$\n",
    "\n",
    "This can be seen in the plot below. Note that each of the grey lines represents the vector $\\vec x$.\n",
    "\n",
    "<img src=\"Parallel lines.png\">\n",
    "\n",
    "## Finding a line that runs through two points (vectors)\n",
    "\n",
    "A line between two points (the head of two vectors) can be found by subtracting one of the vectors from the other and then adding one of the vectors. For example, if we have two vectors, $\\vec a$ and $\\vec b$:\n",
    "\n",
    "$\\vec a = \\begin{bmatrix}2\\\\1\\end{bmatrix}$\n",
    "\n",
    "$\\vec b = \\begin{bmatrix}0\\\\3\\end{bmatrix}$\n",
    "\n",
    "Then we can calculate points that sit on this line by:\n",
    "\n",
    "$\\vec b + 1(\\vec b - \\vec a) = \\begin{bmatrix}0 + 1 \\times (0 - 2) \\\\ 3 + 1 \\times (3 - 1) \\end{bmatrix}$\n",
    "$= \\begin{bmatrix}-2\\\\5\\end{bmatrix}$\n",
    "\n",
    "$\\vec b + 2(\\vec b - \\vec a) = \\begin{bmatrix}0 + 2 \\times (0 - 2) \\\\ 3 + 2 \\times (3 - 1) \\end{bmatrix}$\n",
    "$= \\begin{bmatrix}-4\\\\7\\end{bmatrix}$\n",
    "\n",
    "$\\vec b + -2(\\vec b - \\vec a) = \\begin{bmatrix}0 + -2 \\times (0 - 2) \\\\ 3 + -2 \\times (3 - 1) \\end{bmatrix}$\n",
    "$= \\begin{bmatrix}4\\\\-1\\end{bmatrix}$\n",
    "\n",
    "You can see these points fall on the line in the image below:\n",
    "\n",
    "<img src=\"Drawing a line between two vectors.png\">\n",
    "\n",
    "The formula for the 'x' and 'y' coordinates (in $R^2$) is calculated by taking the x values from $\\vec b$ and $\\vec b - \\vec a$.\n",
    "\n",
    "$\\vec b - \\vec a = \\begin{bmatrix}0 - 2\\\\3 - 1\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}-2\\\\2\\end{bmatrix}$\n",
    "\n",
    "As such:\n",
    "\n",
    "$x = 0 + -2c$\n",
    "$= -2c$\n",
    "\n",
    "$y = 3 + 2c$\n",
    "\n",
    "### Calculating lines in more than 2 dimensions\n",
    "\n",
    "The formula for calculating lines using vectors can be generalised beyond $R^2$. We just need to substitute in 3- (or 4-, or 20-) tuples for the 2-tuples in the previous example. We'll do this with an example in $R^3$:\n",
    "\n",
    "$\\vec P_1 = \\begin{bmatrix}-1\\\\2\\\\7\\end{bmatrix}$\n",
    "\n",
    "$\\vec P_2 = \\begin{bmatrix}0\\\\3\\\\4\\end{bmatrix}$\n",
    "\n",
    "We now need to calculate the difference between $\\vec P_1$ and $\\vec P_2$:\n",
    "\n",
    "$\\vec P_1 - \\vec P_2 = \\begin{bmatrix}-1 - 0\\\\2 - 3\\\\7 - 4\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}-1\\\\-1\\\\3\\end{bmatrix}$\n",
    "\n",
    "We then use this to calculate the formulas for each of the coordinates in ${\\rm I\\!R}^3$ (using $\\vec P_1$ as the vector we add to the difference):\n",
    "\n",
    "$x = -1 + -1c$\n",
    "$= -1 - 1c$\n",
    "\n",
    "$y = 2 + -1c$\n",
    "$= 2 - 1c$\n",
    "\n",
    "$z = 7 + 3c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear combinations of vectors\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/linear-combinations/linear-combinations-and-span/)\n",
    "\n",
    "* A linear combination of vectors is simply 1-n vectors multiplied by some set of scalars (one scalar for each vector) and added together. It is called a linear combination because it is simply addition (we are not multiplying or dividing anything). For example:\n",
    "\n",
    "$\\vec a = \\begin{bmatrix}1\\\\2\\end{bmatrix}$\n",
    "\n",
    "$\\vec b = \\begin{bmatrix}0\\\\3\\end{bmatrix}$\n",
    "\n",
    "A linear combination of these might be:\n",
    "\n",
    "$3 \\vec a + -2 \\vec b = \\begin{bmatrix}3 - 0\\\\6 - 6\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}3\\\\0\\end{bmatrix}$\n",
    "\n",
    "* The **span** of a linear combination is all of the possible vectors it can represent. In the case of the linear combination above, and others such as\n",
    "\n",
    "$\\vec i = \\begin{bmatrix}1\\\\0\\end{bmatrix}$\n",
    "\n",
    "$\\vec j = \\begin{bmatrix}0\\\\1\\end{bmatrix}$\n",
    "\n",
    "the span includes all possible values in ${\\rm I\\!R}^2$. As such, we can say:\n",
    "\n",
    "$Span(\\vec a, \\vec b) = {\\rm I\\!R}^2$\n",
    "\n",
    "However, other linear combinations have a more limited span:\n",
    "* Collinear pairs of vectors can only represent values on the line the vectors lie on\n",
    "* The zero vector can only represent the point 0,0\n",
    "* A single vector can also only represent a line\n",
    "\n",
    "When the span of a linear combination is equal to ${\\rm I\\!R}^2$, you can work out what the vector weights need to be to get any vector in the co-ordinate space. For example, if we represent each of these unknown vector weights with $c$, we get:\n",
    "\n",
    "$c_1 \\vec a + c_2 \\vec b = \\vec x$\n",
    "\n",
    "$c_1 \\begin{bmatrix}1\\\\2\\end{bmatrix} + c_2 \\begin{bmatrix}0\\\\3\\end{bmatrix} = \\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}$\n",
    "\n",
    "$1c_1 + 0c_2 = x_1$\n",
    "\n",
    "$2c_1 + 3c_2 = x_2$\n",
    "\n",
    "Multiply the $x_1$ formula by -2 and add the two together:\n",
    "\n",
    "$-2c_1 = -2x_1$\n",
    "\n",
    "$3c_2 = x_2 - 2x_1$\n",
    "\n",
    "Solve for $c_1$ and $c_2$:\n",
    "\n",
    "$c_2 = \\frac{1}{3}(x_2 - 2x_1)$\n",
    "\n",
    "$c_1 = x_1$\n",
    "\n",
    "So what should $c_1$ and $c_2$ be if we want to reach a vector of $\\begin{bmatrix}2\\\\2\\end{bmatrix}$?\n",
    "\n",
    "$c_1 = 2$\n",
    "\n",
    "$c_2 = \\frac{1}{3}(2 - 2 \\times 2)$\n",
    "$= \\frac{1}{3}(-2)$\n",
    "$= -\\frac{2}{3}$\n",
    "\n",
    "Substituting this into the linear combination for our vectors, we get:\n",
    "\n",
    "$2 \\times \\begin{bmatrix}1\\\\2\\end{bmatrix} + -\\frac{2}{3} \\times \\begin{bmatrix}0\\\\3\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}2\\\\4\\end{bmatrix} - \\begin{bmatrix}0\\\\2\\end{bmatrix}$\n",
    "$= \\begin{bmatrix}2\\\\2\\end{bmatrix}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to linear dependence and independence\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/linear-independence/linear-algebra-introduction-to-linear-independence/)\n",
    "\n",
    "* Linearly independent vectors if they provide new **direction** information to a set - in other words, adding it to a set increases the number of coordinates (in any plane from ${\\rm I\\!R}^2$ upwards) you can represent.\n",
    "* Vectors in a set are linearly dependent if they are providing information that can be represented by a linear combination of vectors already in that set.\n",
    "* Two linearly independent vectors have a span of all of ${\\rm I\\!R}^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on linear independence\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/linear-independence/more-on-linear-independence/)\n",
    "\n",
    "* A set is linearly dependent if for order for $C_1\\vec v_1 + C_2\\vec v_2 + ... + C_n\\vec v_n = \\vec 0$ to be true, at least one $C_i$ must be non-zero.\n",
    "    * That is, in order for the linear combination of all of the vectors in the set to equal the zero vector (e.g., \\begin{bmatrix}0\\\\0\\end{bmatrix}), at least one of the scalar multipliers mustn't equal 0.\n",
    "* In other words, a set is linearly independent if in order for their linear combination to equal the zero vector, all scalar multipliers have to equal zero.\n",
    "* This gives a useful way to test whether a set is linearly independent.\n",
    "* For example, given the set:\n",
    "\n",
    "$\\lbrace\\begin{bmatrix}2\\\\1\\end{bmatrix},\\begin{bmatrix}3\\\\2\\end{bmatrix}\\rbrace$\n",
    "\n",
    "What would the values of $C_1$ and $C_2$ be in order for this to be true?\n",
    "\n",
    "$ C_1 \\begin{bmatrix}2\\\\1\\end{bmatrix} + C_2 \\begin{bmatrix}3\\\\2\\end{bmatrix} = \\begin{bmatrix}0\\\\0\\end{bmatrix}$\n",
    "\n",
    "We can solve this algebraically:\n",
    "\n",
    "$$\\begin{eqnarray} \n",
    "2C_1 + 3C_2 &=& 0 \\cr\n",
    "C_1 + 2C_2 &=& 0 \\cr\n",
    "C_1 + \\frac{3}{2}C_2 &=& 0 \\cr \n",
    "\\frac{1}{2}C_2 &=& 0 \\cr\n",
    "C_2 &=& 0 \\cr\n",
    "C_1 &=& 0 \\cr\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "Because $C_1$ and $C_2$ are 0, the set is linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Span and linear independence\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/linear-independence/span-and-linear-independence-example/)\n",
    "\n",
    "* Example in the video of solving linear combination and testing for linear independence for set of 3-tuples. \n",
    "* The minimum number of 3-tuples needed to span ${\\rm I\\!R}^3$ is 3 - any less than there will not be sufficient information about direction in order to represent all co-ordinates in this space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear subspaces\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/subspace-basis/linear-subspaces/)\n",
    "\n",
    "* A subset is just some restricted group of all of the possible co-ordinates in ${\\rm I\\!R}^n$.\n",
    "* A subset qualifies as a subspace if it meants the following conditions:\n",
    "    * It contains the zero vector\n",
    "    * It has closure under scalar multiplication (any scaled version of a vector in the subspace is also in the subspace)\n",
    "    * It has closure under addition (the result of adding any two vectors within the subspace is also in the subspace)\n",
    "* The span of n vectors is a valid subspace of ${\\rm I\\!R}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis of a subspace\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/subspace-basis/linear-algebra-basis-of-a-subspace/)\n",
    "\n",
    "* A basis is:\n",
    "    * A set of vectors that spans a subspace that is\n",
    "    * Linearly independent\n",
    "* A basis is therefore the minimum set of information needed to construct a subspace (represent all coordinates in that subspace with a linear combinations of all vectors in the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector dot product and vector length\n",
    "\n",
    "* Dot product is found by multiplying the first element of vector 1 by the first element of vector 2, and so on, and then adding the whole thing together.\n",
    "* The result of a dot product is therefore a scalar\n",
    "* You must use $\\cdot$ rather than $\\times$, as these are distinct concepts\n",
    "* For example:\n",
    "\n",
    "$p = \\begin{bmatrix}-2\\\\2\\end{bmatrix} \\cdot \\begin{bmatrix}5\\\\1\\end{bmatrix} = \\begin{bmatrix}-2 \\cdot 5\\\\2 \\cdot 1\\end{bmatrix} = -10 + 2 = -8$ \n",
    "\n",
    "* The magnitude (or length) of a vector can also be calculated by taking square root of the sum of squared elements of the vector\n",
    "* For example, for vector l:\n",
    "\n",
    "$l = \\begin{bmatrix}4\\\\2\\\\7\\\\2\\\\1\\end{bmatrix} $\n",
    "\n",
    "the length, $\\lVert l \\rVert$ will be:\n",
    "\n",
    "$\\lVert l \\rVert = \\sqrt{4^2 + 2^2 + 7^2 + 2^2 + 1^2} = \\sqrt{74}$\n",
    "\n",
    "* This can be represented with the dot product like so:\n",
    "\n",
    "$\\lVert l \\rVert = \\sqrt{\\begin{bmatrix}4\\\\2\\\\7\\\\2\\\\1\\end{bmatrix} \\cdot \\begin{bmatrix}4\\\\2\\\\7\\\\2\\\\1\\end{bmatrix}}$\n",
    "\n",
    "* Alternatively:\n",
    "\n",
    "$\\lVert l^2 \\rVert = \\begin{bmatrix}4\\\\2\\\\7\\\\2\\\\1\\end{bmatrix} \\cdot \\begin{bmatrix}4\\\\2\\\\7\\\\2\\\\1\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proving vector dot product properties\n",
    "\n",
    "Does the dot product demonstrate the following properties of multiplication? These are properties associated with the multiplication of regular scalars (numbers).\n",
    "\n",
    "### Commutative property\n",
    "\n",
    "$\\vec v \\cdot \\vec w$ is the same as $\\vec w \\cdot \\vec v$:\n",
    "\n",
    "$\\vec v = \\begin{bmatrix}v_1\\\\v_2\\\\ \\cdots \\\\v_n\\end{bmatrix}$\n",
    "\n",
    "$\\vec w = \\begin{bmatrix}w_1\\\\w_2\\\\ \\cdots \\\\w_n\\end{bmatrix}$\n",
    "\n",
    "If we take $\\vec v \\cdot \\vec w$, we get:\n",
    "\n",
    "$\\vec v \\cdot \\vec w = v_1w_1 + v_2w_2 + \\ldots + v_nw_n$\n",
    "\n",
    "Equivalently, if we take $\\vec w \\cdot \\vec v$, we get:\n",
    "\n",
    "$\\vec w \\cdot \\vec v = w_1v_1 + w_2v_2 + \\ldots + w_nv_n$\n",
    "\n",
    "which is the exact same thing. The vector dot property therefre has the **commutative property of multiplication.**\n",
    "\n",
    "### Distributative property\n",
    "\n",
    "$(\\vec v + \\vec w) \\cdot \\vec x$ is the same as $(\\vec v \\cdot \\vec x + \\vec w \\cdot \\vec x)$. This is demonstrated by:\n",
    "\n",
    "$\\vec x = \\begin{bmatrix}x_1\\\\x_2\\\\ \\cdots \\\\x_n\\end{bmatrix}$\n",
    "\n",
    "To start with:\n",
    "\n",
    "$\\begin{eqnarray} \n",
    "(\\vec v + \\vec w) \\cdot \\vec x &=& \\begin{bmatrix}v_1 + w_1\\\\v_2 + w_2\\\\ \\cdots \\\\v_n + w_n\\end{bmatrix} \\cdot \\begin{bmatrix}x_1\\\\x_2\\\\ \\cdots \\\\x_n\\end{bmatrix} \\cr\n",
    "&=& (v_1 + w_1)x_1 + (v_2 + w_2)x_2 + \\ldots + (v_n + w_n)x_n \\cr\n",
    "\\end{eqnarray}$\n",
    "\n",
    "Moving on to the other side of the equation:\n",
    "\n",
    "$\\vec v \\cdot \\vec x = v_1x_1 + v_2x_2 + \\ldots + v_nx_n$\n",
    "\n",
    "$\\vec w \\cdot \\vec x = w_1x_1 + w_2x_2 + \\ldots + w_nx_n$\n",
    "\n",
    "$\\begin{eqnarray} \n",
    "\\vec v \\cdot \\vec x + \\vec w \\cdot \\vec x &=& (v_1x_1 + w_1x_1) + (v_2x_2 + w_2x_2) + \\ldots + (v_nx_n + w_nx_n) \\cr\n",
    "&=& (v_1 + w_1)x_1 + (v_2 + w_2)x_2 + \\ldots + (v_n + w_n)x_n \\cr\n",
    "\\end{eqnarray}$\n",
    "\n",
    "You can see they are equivalent, therefore the dot product demonstrates the distributative property of multiplication.\n",
    "\n",
    "### Associative property\n",
    "\n",
    "$(c \\vec v) \\cdot \\vec w$ is the same as $c(\\vec v \\cdot \\vec w)$. This is proven by:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "(c \\vec v) \\cdot \\vec w &=& \\begin{bmatrix}cv_1\\\\cv_2\\\\ \\cdots \\\\cv_n\\end{bmatrix} \\cdot \\begin{bmatrix}w_1\\\\w_2\\\\ \\cdots \\\\w_n\\end{bmatrix} \\cr\n",
    "&=& cv_1w_1 + cv_2w_2 + \\ldots + cv_nw_n \\cr\n",
    "\\end{eqnarray}$\n",
    "\n",
    "Equivalently:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "c(\\vec v \\cdot \\vec w) &=& c \\cdot \\begin{bmatrix}v_1w_1\\\\v_2w_2\\\\ \\cdots \\\\v_nw_n\\end{bmatrix} \\cr\n",
    "&=& cv_1w_1 + cv_2w_2 + \\ldots + cv_nw_n \\cr\n",
    "\\end{eqnarray}$\n",
    "\n",
    "The dot product therefore demonstrates the associative property of multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cauchy-Schwartz inequality\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/dot-cross-products/proof-of-the-cauchy-schwarz-inequality/)\n",
    "\n",
    "This video gives the proof for the **Cauchy-Schwartz inequality**, which is that for non-zero vectors $\\vec x$ and $\\vec y$ which are part of ${\\rm I\\!R}^n$ (i.e., neither $\\vec x$ nor $\\vec y$ are the zero vector):\n",
    "\n",
    "$$\\left|\\vec x\\cdot\\vec y\\right| \\le \\left|\\left|\\vec x \\right|\\right| \\left|\\left|\\vec y \\right|\\right|$$\n",
    "\n",
    "In other words, the absolute dot product of vectors $\\vec x$ and $\\vec y$ is less than or equal to the product of their lengths. Moreover:\n",
    "\n",
    "$$\\left|\\vec x\\cdot\\vec y\\right| = \\left|\\left|\\vec x \\right|\\right| \\left|\\left|\\vec y \\right|\\right| \\iff \\vec x = c\\vec y$$\n",
    "\n",
    "In other words, the absolute dot product of vectors $\\vec x$ and $\\vec y$ is only equal to the product of their lengths if (and only if) $\\vec x$ is some scalar product of/collinear with $\\vec y$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Vector triangle inequality\n",
    "\n",
    "Link [here.](http://127.0.0.1:8008/learn/khan/math/linear-algebra/vectors-and-spaces/dot-cross-products/linear-algebra-vector-triangle-inequality/)\n",
    "\n",
    "This video gives the proof for the **triangle inequality**, which is that for non-zero vectors $\\vec x$ and $\\vec y$ which are part of ${\\rm I\\!R}^n$ (i.e., neither $\\vec x$ nor $\\vec y$ are the zero vector):\n",
    "\n",
    "$$\\left|\\left|\\vec x + \\vec y\\right|\\right| \\le \\left|\\left| \\vec x \\right|\\right| + \\left|\\left| \\vec y \\right|\\right|$$\n",
    "\n",
    "In other words, the length of $\\vec x + \\vec y$ is less than the length of $\\vec x$ plus the length of $\\vec y$. This is obvious for ${\\rm I\\!R}^2$ in the below diagram:\n",
    "\n",
    "<img src=\"Triangle inequality 1.png\">\n",
    "\n",
    "You can see above that the path to reach $\\begin{bmatrix}2\\\\3\\end{bmatrix}$ is much shorter through $\\vec x + \\vec y$ than through $\\vec x$ then $\\vec y$, which is basically all that the triangle inequality is saying. Generalising this in a formula means we can represent this rule in plane greater than ${\\rm I\\!R}^2$.\n",
    "\n",
    "As with the Cauchy-Schwartz inequality, the only condition under which the two sides are equal is when $\\vec x$ is a scalar multiple of $\\vec y$.\n",
    "\n",
    "$$\\left|\\left|\\vec x + \\vec y\\right|\\right| = \\left|\\left| \\vec x \\right|\\right| + \\left|\\left| \\vec y \\right|\\right| \\iff \\vec x = c\\vec y$$\n",
    "\n",
    "You can again see this really easily when visualised in ${\\rm I\\!R}^2$:\n",
    "\n",
    "<img src=\"Triangle inequality 2.png\">\n",
    "\n",
    "Because the two vectors are collinear, they are already travelling the most efficient path to get to $\\begin{bmatrix}3\\\\6\\end{bmatrix}$. As such, their addition must also lie on this same line, therefore it has the same length as the length of each vector added together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Defining the angle between vectors\n",
    "\n",
    "As a refresher, we can represent the subtraction of two vectors $\\vec a$ and $\\vec b$ as so:\n",
    "\n",
    "<img src=\"Angle between vectors 1.png\">\n",
    "\n",
    "As you can see, we are trying to represent the angle between the two vectors.\n",
    "\n",
    "This can be converted to a triangle with sides the length of each vector, as below:\n",
    "\n",
    "<img src=\"Angle between vectors 2.png\">\n",
    "\n",
    "The angle in this triangle is equivalent to the one between $\\vec a$ and $\\vec b$, so if we can find this angle in the triangle we can work out what the angle is between our vectors. It also turns out that for any pair of non-zero vectors, it is possible to construct a triangle like this (see video for proof).\n",
    "\n",
    "The **law of cosines** says that for *any* triangle, we can find out the size of this angle $\\theta$. This law is:\n",
    "\n",
    "$$C^2 = A^2 + B^2 - 2AB \\cos(\\theta)$$\n",
    "\n",
    "We can simplify this law for finding the angle on our triangle as below:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "\\left|\\left|\\vec a - \\vec b\\right|\\right|^2 &=& \\left|\\left|\\vec a\\right|\\right|^2 + \\left|\\left|\\vec b\\right|\\right|^2 - 2\\left|\\left|\\vec a\\right|\\right|\\left|\\left|\\vec b\\right|\\right| \\cos(\\theta) \\cr\n",
    "(\\vec a - \\vec b)\\cdot(\\vec a - \\vec b) &=& \\left|\\left|\\vec a\\right|\\right|^2 + \\left|\\left|\\vec b\\right|\\right|^2 - 2\\left|\\left|\\vec a\\right|\\right|\\left|\\left|\\vec b\\right|\\right| \\cos(\\theta) \\cr\n",
    "\\vec a\\cdot\\vec a - \\vec a\\cdot\\vec b - \\vec b\\cdot\\vec a + \\vec b\\cdot\\vec b &=& \\left|\\left|\\vec a\\right|\\right|^2 + \\left|\\left|\\vec b\\right|\\right|^2 - 2\\left|\\left|\\vec a\\right|\\right|\\left|\\left|\\vec b\\right|\\right| \\cos(\\theta) \\cr\n",
    "\\left|\\left|\\vec a\\right|\\right|^2 - 2(\\vec a \\cdot \\vec b) + \\left|\\left|\\vec b\\right|\\right|^2 &=& \\left|\\left|\\vec a\\right|\\right|^2 + \\left|\\left|\\vec b\\right|\\right|^2 - 2\\left|\\left|\\vec a\\right|\\right|\\left|\\left|\\vec b\\right|\\right| \\cos(\\theta) \\cr\n",
    "- 2(\\vec a \\cdot \\vec b) &=& - 2\\left|\\left|\\vec a\\right|\\right|\\left|\\left|\\vec b\\right|\\right| \\cos(\\theta) \\cr\n",
    "(\\vec a \\cdot \\vec b) &=& \\left|\\left|\\vec a\\right|\\right|\\left|\\left|\\vec b\\right|\\right| \\cos(\\theta) \\cr\n",
    "\\end{eqnarray}$\n",
    "\n",
    "This law works for all pairs of non-zero vectors. Collinearity is as usual a special case. When $\\vec a = c\\vec b$, then:\n",
    "\n",
    "$c > 0 \\implies \\theta = 0째$\n",
    "\n",
    "$c < 0 \\implies \\theta = 180째$\n",
    "\n",
    "### Perpendicular vs orthogonal angles\n",
    "\n",
    "Angles are perpendicular when $\\theta = 90째$. This means that:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "(\\vec a \\cdot \\vec b) &=& \\left|\\left|\\vec a\\right|\\right|\\left|\\left|\\vec b\\right|\\right| \\cos(90째) \\cr\n",
    "(\\vec a \\cdot \\vec b) &=& \\left|\\left|\\vec a\\right|\\right|\\left|\\left|\\vec b\\right|\\right| 0 \\cr\n",
    "(\\vec a \\cdot \\vec b) &=& 0\n",
    "\\end{eqnarray}$\n",
    "\n",
    "Vectors are **perpendicular** when $(\\vec a \\cdot \\vec b) = 0$ and $\\vec a$ and $\\vec b$ are non-zero. However, vectors do not need to be non-zero to be **orthogonal**. This means that the zero vector is not perpendicular, but it is orthogonal. It also means that the zero vector is orthogonal to everything, including itself! This can be see by substituting in the zero vector to our condition for orthogonality:\n",
    "\n",
    "$\\begin{eqnarray}\n",
    "\\left(\\begin{bmatrix}0\\\\0\\end{bmatrix} \\cdot \\begin{bmatrix}1\\\\4\\end{bmatrix}\\right) &=& 0 \\cr\n",
    "(0 \\cdot 1) + (0 \\cdot 4) &=& 0 \\cr\n",
    "0 &=& 0\n",
    "\\end{eqnarray}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
